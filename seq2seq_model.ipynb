{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### start from baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-addons\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "print(tf.__version__)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import shutil\n",
    "import zipfile\n",
    "import itertools\n",
    "#from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"./bwd_sample100.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "  w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [equation, integral]\n",
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> * 4 * acos 3 cosh x <end>\n",
      "<start> * 2 * + 8 + * 2 sinh x * + 4 * -1 pi tan / 41 2 acos 3 <end>\n"
     ]
    }
   ],
   "source": [
    "eq, intgr = create_dataset(path_to_file, None)\n",
    "print(eq[-1])\n",
    "print(intgr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text, Y_text = create_dataset(path_to_file, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to tokenize words into index using inbuild tokenizer vocabulory\n",
    "def tokenize(input):\n",
    "   tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "   tokenizer.fit_on_texts(input)\n",
    "   sequences = tokenizer.texts_to_sequences(input)\n",
    "  # print(max_len(sequences))\n",
    "   sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
    "   return  sequences, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_len(tensor):\n",
    "    #print( np.argmax([len(t) for t in tensor]))\n",
    "    return max( len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize each word into index and return the tokenized list and tokenizer\n",
    "X , X_tokenizer = tokenize(X_text)\n",
    "Y, Y_tokenizer = tokenize(Y_text)\n",
    "X_train,  X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "Tx = max_len(X)\n",
    "Ty = max_len(Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 152)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length  equation sentence denoted as Tx :  152\n",
      "Max length intergral sentence denoted as Ty:  40\n"
     ]
    }
   ],
   "source": [
    "print(\"Max length  equation sentence denoted as Tx : \", Tx)\n",
    "print(\"Max length intergral sentence denoted as Ty: \", Ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_vocab_size :  62\n",
      "output_vocab_size :  66\n"
     ]
    }
   ],
   "source": [
    "X_tokenizer.word_index['<start>'] #'<start>': 2   # tokenize by frequency\n",
    "input_vocab_size = len(X_tokenizer.word_index)+1  # add 1 for 0 sequence character\n",
    "output_vocab_size = len(Y_tokenizer.word_index)+ 1\n",
    "print(\"input_vocab_size : \", input_vocab_size)\n",
    "print(\"output_vocab_size : \" ,output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'*': 1,\n",
       " '+': 2,\n",
       " 'pow': 3,\n",
       " 'x': 4,\n",
       " '-1': 5,\n",
       " '2': 6,\n",
       " '<start>': 7,\n",
       " '/': 8,\n",
       " '<end>': 9,\n",
       " '1': 10,\n",
       " '3': 11,\n",
       " '5': 12,\n",
       " '4': 13,\n",
       " '-2': 14,\n",
       " 'cos': 15,\n",
       " 'sinh': 16,\n",
       " 'exp': 17,\n",
       " 'cosh': 18,\n",
       " 'tan': 19,\n",
       " '-3': 20,\n",
       " 'sin': 21,\n",
       " 'tanh': 22,\n",
       " '-4': 23,\n",
       " '0': 24,\n",
       " 'log': 25,\n",
       " 'asin': 26,\n",
       " 'acos': 27,\n",
       " '-5': 28,\n",
       " 'atan': 29,\n",
       " 'acosh': 30,\n",
       " '-10': 31,\n",
       " 'atanh': 32,\n",
       " 'asinh': 33,\n",
       " '6': 34,\n",
       " '20': 35,\n",
       " '9': 36,\n",
       " '16': 37,\n",
       " 'pi': 38,\n",
       " '8': 39,\n",
       " '15': 40,\n",
       " '-20': 41,\n",
       " '-15': 42,\n",
       " '-25': 43,\n",
       " '-8': 44,\n",
       " '25': 45,\n",
       " '7': 46,\n",
       " '18': 47,\n",
       " '-17': 48,\n",
       " '-6': 49,\n",
       " '1250': 50,\n",
       " '100': 51,\n",
       " '-18': 52,\n",
       " '-16': 53,\n",
       " 'sign(x)': 54,\n",
       " '10': 55,\n",
       " '21': 56,\n",
       " '-9': 57,\n",
       " '-200': 58,\n",
       " '80': 59,\n",
       " '24': 60,\n",
       " '-60': 61}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 152)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  6,  5,  4,  8, 13,  4,  9,  5, 14, 15,  6,  3,  2],\n",
       "       [ 1,  4,  9, 10,  5,  3,  4,  8,  6,  7,  3,  6,  2,  0,  0],\n",
       "       [ 1,  7,  3, 11,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1, 10,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "BUFFER_SIZE = len(X_train)\n",
    "steps_per_epoch = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dims = 256\n",
    "rnn_units = 1024\n",
    "dense_units = 1024\n",
    "Dtype = tf.float32   #used to initialize DecoderCell Zero state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 152)\n",
      "(10, 40)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "example_X, example_Y = next(iter(dataset))\n",
    "print(example_X.shape) \n",
    "print(example_Y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 152)\n",
      "(10, 40)\n"
     ]
    }
   ],
   "source": [
    "dataset_test = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "example_X, example_Y = next(iter(dataset))\n",
    "print(example_X.shape) \n",
    "print(example_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Encoder-Decoder Model based on tfa.seq2seq module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model\n",
    "\n",
    "The encoder network consists of an encoder embedding layer and a LSTM layer.\n",
    "\n",
    "The decoder network encompasses both decoder and attention mechanism.\n",
    "\n",
    "The attention uses LuongAttention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODER\n",
    "class EncoderNetwork(tf.keras.Model):\n",
    "    def __init__(self,input_vocab_size,embedding_dims, rnn_units ):\n",
    "        super().__init__()\n",
    "        self.encoder_embedding = tf.keras.layers.Embedding(input_dim=input_vocab_size,\n",
    "                                                           output_dim=embedding_dims)\n",
    "        self.encoder_rnnlayer = tf.keras.layers.LSTM(rnn_units,return_sequences=True, \n",
    "                                                     return_state=True )\n",
    "    \n",
    "#DECODER\n",
    "class DecoderNetwork(tf.keras.Model):\n",
    "    def __init__(self,output_vocab_size, embedding_dims, rnn_units):\n",
    "        super().__init__()\n",
    "        self.decoder_embedding = tf.keras.layers.Embedding(input_dim=output_vocab_size,\n",
    "                                                           output_dim=embedding_dims) \n",
    "        self.dense_layer = tf.keras.layers.Dense(output_vocab_size)\n",
    "        self.decoder_rnncell = tf.keras.layers.LSTMCell(rnn_units)\n",
    "        # Sampler\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "        # Create attention mechanism with memory = None\n",
    "        self.attention_mechanism = self.build_attention_mechanism(dense_units,None,BATCH_SIZE*[Tx])\n",
    "        self.rnn_cell =  self.build_rnn_cell(BATCH_SIZE)\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler= self.sampler,\n",
    "                                                output_layer=self.dense_layer)\n",
    "\n",
    "    def build_attention_mechanism(self, units,memory, memory_sequence_length):\n",
    "        return tfa.seq2seq.LuongAttention(units, memory = memory, \n",
    "                                          memory_sequence_length=memory_sequence_length)\n",
    "        #return tfa.seq2seq.BahdanauAttention(units, memory = memory, memory_sequence_length=memory_sequence_length)\n",
    "\n",
    "    # wrap decodernn cell  \n",
    "    def build_rnn_cell(self, batch_size ):\n",
    "        rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnncell, self.attention_mechanism,\n",
    "                                                attention_layer_size=dense_units)\n",
    "        return rnn_cell\n",
    "    \n",
    "    def build_decoder_initial_state(self, batch_size, encoder_state,Dtype):\n",
    "        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size = batch_size, \n",
    "                                                                dtype = Dtype)\n",
    "        decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state) \n",
    "        return decoder_initial_state\n",
    "\n",
    "\n",
    "\n",
    "encoderNetwork = EncoderNetwork(input_vocab_size,embedding_dims, rnn_units)\n",
    "decoderNetwork = DecoderNetwork(output_vocab_size,embedding_dims, rnn_units)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second way of define encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.lstm = tf.keras.layers.LSTM(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True\n",
    "                                    )\n",
    "\n",
    "  def __call__(self, x, initial_state):\n",
    "    x = self.embedding(x)\n",
    "    output, state_h, state_cell = self.lstm(x, initial_state = initial_state)\n",
    "    return output, state_h, state_cell\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return  [tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (10, 152, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (10, 1024)\n",
      "Encoder cell state shape: (batch size, units) (10, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(input_vocab_size, embedding_dims, rnn_units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "initial_state = encoder.initialize_hidden_state()\n",
    "sample_output, sample_h, sample_c = encoder(example_X, initial_state)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_h.shape))\n",
    "print ('Encoder cell state shape: (batch size, units) {}'.format(sample_c.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def __call__(self, query, values):\n",
    "    # hidden shape == (batch_size, hidden size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # we are doing this to perform addition to calculate the score\n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (10, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (10, 152, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_h, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (10, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (10, 152, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_h, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 152, 1024])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 1, 1024])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(sample_h, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.lstm = tf.keras.layers.LSTM(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   )\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def __call__(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "     \n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the lstm\n",
    "    output, state_h, state_c = self.lstm(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state_h, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (10, 66)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(output_vocab_size, embedding_dims, rnn_units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_h, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, mask is a zero-one matrix of the same size as decoder_outputs. It masks padding positions outside of the target sequence lengths with values 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_pred, y):\n",
    "   \n",
    "    #shape of y [batch_size, ty]\n",
    "    #shape of y_pred [batch_size, Ty, output_vocab_size] \n",
    "    sparsecategoricalcrossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                                                  reduction='none')\n",
    "    loss = sparsecategoricalcrossentropy(y_true=y, y_pred=y_pred)\n",
    "    #skip loss calculation for padding sequences i.e. y = 0 \n",
    "    #[ <start>,How, are, you, today, 0, 0, 0, 0 ....<end>]\n",
    "    #[ 1, 234, 3, 423, 3344, 0, 0 ,0 ,0, 2 ]\n",
    "    # y is a tensor of [batch_size,Ty] . Create a mask when [y=0]\n",
    "    # mask the loss when padding sequence appears in the output sequence\n",
    "    mask = tf.logical_not(tf.math.equal(y,0))   #output 0 for y=0 else output 1\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss = mask* loss\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, attention mechanism is initialized without memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoderNetwork.attention_mechanism.memory_initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input_batch, output_batch,encoder_initial_cell_state):\n",
    "    #initialize loss = 0\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoder_emb_inp = encoderNetwork.encoder_embedding(input_batch)\n",
    "        #print(encoder_emb_inp.shape)\n",
    "        a, a_tx, c_tx = encoderNetwork.encoder_rnnlayer(encoder_emb_inp, \n",
    "                                                        initial_state =encoder_initial_cell_state)\n",
    "        #print(a.shape)\n",
    "        #[last step activations,last memory_state] of encoder passed as input to decoder Network\n",
    "        \n",
    "\n",
    "         \n",
    "        # Prepare correct Decoder input & output sequence data\n",
    "        decoder_input = output_batch[:,:-1] # ignore <end>\n",
    "        #compare logits with timestepped +1 version of decoder_input\n",
    "        decoder_output = output_batch[:,1:] #ignore <start>\n",
    "\n",
    "\n",
    "        # Decoder Embeddings\n",
    "        decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_input)\n",
    "\n",
    "        #Setting up decoder memory from encoder output and Zero State for AttentionWrapperState\n",
    "        decoderNetwork.attention_mechanism.setup_memory(a)\n",
    "        decoder_initial_state = decoderNetwork.build_decoder_initial_state(BATCH_SIZE,\n",
    "                                                                           encoder_state=[a_tx, c_tx],\n",
    "                                                                           Dtype=tf.float32)\n",
    "\n",
    "        #BasicDecoderOutput        \n",
    "        outputs, _, _ = decoderNetwork.decoder(decoder_emb_inp,initial_state=decoder_initial_state,\n",
    "                                               sequence_length=BATCH_SIZE*[Ty-1])\n",
    "\n",
    "        logits = outputs.rnn_output\n",
    "        #Calculate loss\n",
    "\n",
    "        loss = loss_function(logits, decoder_output)\n",
    "\n",
    "    #Returns the list of all layer variables / weights.\n",
    "    variables = encoderNetwork.trainable_variables + decoderNetwork.trainable_variables  \n",
    "    # differentiate loss wrt variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    #grads_and_vars – List of(gradient, variable) pairs.\n",
    "    grads_and_vars = zip(gradients,variables)\n",
    "    optimizer.apply_gradients(grads_and_vars)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN LSTM hidden and memory state initializer\n",
    "def initialize_initial_state():\n",
    "        return [tf.zeros((BATCH_SIZE, rnn_units)), tf.zeros((BATCH_SIZE, rnn_units))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: 1.8886302709579468 epoch 1 batch 1 \n",
      "total loss: 1.8877029418945312 epoch 1 batch 2 \n",
      "total loss: 4.551619052886963 epoch 1 batch 3 \n",
      "total loss: 2.1490538120269775 epoch 1 batch 4 \n",
      "total loss: 1.7772051095962524 epoch 1 batch 5 \n",
      "total loss: 2.447599172592163 epoch 1 batch 6 \n",
      "total loss: 1.3594917058944702 epoch 1 batch 7 \n",
      "total loss: 1.9497156143188477 epoch 1 batch 8 \n",
      "total loss: 1.940775752067566 epoch 2 batch 1 \n",
      "total loss: 1.6381129026412964 epoch 2 batch 2 \n",
      "total loss: 1.599976658821106 epoch 2 batch 3 \n",
      "total loss: 1.7171744108200073 epoch 2 batch 4 \n",
      "total loss: 1.828129529953003 epoch 2 batch 5 \n",
      "total loss: 1.2986836433410645 epoch 2 batch 6 \n",
      "total loss: 1.2539727687835693 epoch 2 batch 7 \n",
      "total loss: 1.452532172203064 epoch 2 batch 8 \n",
      "total loss: 1.2416516542434692 epoch 3 batch 1 \n",
      "total loss: 1.5078916549682617 epoch 3 batch 2 \n",
      "total loss: 1.3181312084197998 epoch 3 batch 3 \n",
      "total loss: 1.5626060962677002 epoch 3 batch 4 \n",
      "total loss: 1.4508190155029297 epoch 3 batch 5 \n",
      "total loss: 1.3252592086791992 epoch 3 batch 6 \n",
      "total loss: 1.6304317712783813 epoch 3 batch 7 \n",
      "total loss: 1.6641204357147217 epoch 3 batch 8 \n",
      "total loss: 1.403885006904602 epoch 4 batch 1 \n",
      "total loss: 1.4832159280776978 epoch 4 batch 2 \n",
      "total loss: 1.3910788297653198 epoch 4 batch 3 \n",
      "total loss: 1.5369784832000732 epoch 4 batch 4 \n",
      "total loss: 1.4027985334396362 epoch 4 batch 5 \n",
      "total loss: 1.2219558954238892 epoch 4 batch 6 \n",
      "total loss: 1.5596835613250732 epoch 4 batch 7 \n",
      "total loss: 1.354038953781128 epoch 4 batch 8 \n",
      "total loss: 1.8734866380691528 epoch 5 batch 1 \n",
      "total loss: 1.305094838142395 epoch 5 batch 2 \n",
      "total loss: 1.3216502666473389 epoch 5 batch 3 \n",
      "total loss: 1.1115789413452148 epoch 5 batch 4 \n",
      "total loss: 1.5432814359664917 epoch 5 batch 5 \n",
      "total loss: 1.4151896238327026 epoch 5 batch 6 \n",
      "total loss: 1.4384125471115112 epoch 5 batch 7 \n",
      "total loss: 1.1761621236801147 epoch 5 batch 8 \n",
      "total loss: 1.2185869216918945 epoch 6 batch 1 \n",
      "total loss: 1.1477940082550049 epoch 6 batch 2 \n",
      "total loss: 1.466647744178772 epoch 6 batch 3 \n",
      "total loss: 1.3894745111465454 epoch 6 batch 4 \n",
      "total loss: 1.6032980680465698 epoch 6 batch 5 \n",
      "total loss: 1.2006500959396362 epoch 6 batch 6 \n",
      "total loss: 1.458581805229187 epoch 6 batch 7 \n",
      "total loss: 1.4784255027770996 epoch 6 batch 8 \n",
      "total loss: 4.091254234313965 epoch 7 batch 1 \n",
      "total loss: 1.0737472772598267 epoch 7 batch 2 \n",
      "total loss: 1.3585411310195923 epoch 7 batch 3 \n",
      "total loss: 1.7155218124389648 epoch 7 batch 4 \n",
      "total loss: 1.5637295246124268 epoch 7 batch 5 \n",
      "total loss: 1.2247412204742432 epoch 7 batch 6 \n",
      "total loss: 1.3154616355895996 epoch 7 batch 7 \n",
      "total loss: 1.3878207206726074 epoch 7 batch 8 \n",
      "total loss: 1.042696475982666 epoch 8 batch 1 \n",
      "total loss: 1.3278342485427856 epoch 8 batch 2 \n",
      "total loss: 1.425957441329956 epoch 8 batch 3 \n",
      "total loss: 1.4000049829483032 epoch 8 batch 4 \n",
      "total loss: 1.1130905151367188 epoch 8 batch 5 \n",
      "total loss: 1.6037697792053223 epoch 8 batch 6 \n",
      "total loss: 1.3737436532974243 epoch 8 batch 7 \n",
      "total loss: 1.5543378591537476 epoch 8 batch 8 \n",
      "total loss: 1.3678313493728638 epoch 9 batch 1 \n",
      "total loss: 1.3322807550430298 epoch 9 batch 2 \n",
      "total loss: 1.3116704225540161 epoch 9 batch 3 \n",
      "total loss: 1.274461030960083 epoch 9 batch 4 \n",
      "total loss: 1.276119351387024 epoch 9 batch 5 \n",
      "total loss: 1.4550132751464844 epoch 9 batch 6 \n",
      "total loss: 1.211118221282959 epoch 9 batch 7 \n",
      "total loss: 1.2419389486312866 epoch 9 batch 8 \n",
      "total loss: 1.3939157724380493 epoch 10 batch 1 \n",
      "total loss: 1.2297006845474243 epoch 10 batch 2 \n",
      "total loss: 1.1959189176559448 epoch 10 batch 3 \n",
      "total loss: 1.2226035594940186 epoch 10 batch 4 \n",
      "total loss: 1.3786267042160034 epoch 10 batch 5 \n",
      "total loss: 1.4342395067214966 epoch 10 batch 6 \n",
      "total loss: 1.2917122840881348 epoch 10 batch 7 \n",
      "total loss: 1.0259146690368652 epoch 10 batch 8 \n",
      "total loss: 1.0627745389938354 epoch 11 batch 1 \n",
      "total loss: 1.1901663541793823 epoch 11 batch 2 \n",
      "total loss: 1.4001142978668213 epoch 11 batch 3 \n",
      "total loss: 1.4138116836547852 epoch 11 batch 4 \n",
      "total loss: 1.2806295156478882 epoch 11 batch 5 \n",
      "total loss: 1.1954346895217896 epoch 11 batch 6 \n",
      "total loss: 1.212260127067566 epoch 11 batch 7 \n",
      "total loss: 1.195356845855713 epoch 11 batch 8 \n",
      "total loss: 1.2744983434677124 epoch 12 batch 1 \n",
      "total loss: 0.9967360496520996 epoch 12 batch 2 \n",
      "total loss: 1.442035436630249 epoch 12 batch 3 \n",
      "total loss: 1.112343668937683 epoch 12 batch 4 \n",
      "total loss: 1.4309262037277222 epoch 12 batch 5 \n",
      "total loss: 1.4660004377365112 epoch 12 batch 6 \n",
      "total loss: 0.8665091395378113 epoch 12 batch 7 \n",
      "total loss: 0.9237728118896484 epoch 12 batch 8 \n",
      "total loss: 1.1131671667099 epoch 13 batch 1 \n",
      "total loss: 1.148725986480713 epoch 13 batch 2 \n",
      "total loss: 1.242376685142517 epoch 13 batch 3 \n",
      "total loss: 1.1249890327453613 epoch 13 batch 4 \n",
      "total loss: 0.8945918083190918 epoch 13 batch 5 \n",
      "total loss: 1.314980387687683 epoch 13 batch 6 \n",
      "total loss: 1.2516824007034302 epoch 13 batch 7 \n",
      "total loss: 1.1495616436004639 epoch 13 batch 8 \n",
      "total loss: 1.2074306011199951 epoch 14 batch 1 \n",
      "total loss: 1.161692500114441 epoch 14 batch 2 \n",
      "total loss: 1.1363098621368408 epoch 14 batch 3 \n",
      "total loss: 1.152111291885376 epoch 14 batch 4 \n",
      "total loss: 0.8813188672065735 epoch 14 batch 5 \n",
      "total loss: 1.1868512630462646 epoch 14 batch 6 \n",
      "total loss: 1.1422322988510132 epoch 14 batch 7 \n",
      "total loss: 1.1392059326171875 epoch 14 batch 8 \n",
      "total loss: 1.0869052410125732 epoch 15 batch 1 \n",
      "total loss: 0.8528062105178833 epoch 15 batch 2 \n",
      "total loss: 0.9609196782112122 epoch 15 batch 3 \n",
      "total loss: 0.7902216911315918 epoch 15 batch 4 \n",
      "total loss: 1.151320219039917 epoch 15 batch 5 \n",
      "total loss: 1.3134384155273438 epoch 15 batch 6 \n",
      "total loss: 1.2652277946472168 epoch 15 batch 7 \n",
      "total loss: 1.1807878017425537 epoch 15 batch 8 \n",
      "total loss: 1.1144155263900757 epoch 16 batch 1 \n",
      "total loss: 1.0318102836608887 epoch 16 batch 2 \n",
      "total loss: 0.9036642909049988 epoch 16 batch 3 \n",
      "total loss: 0.9025288820266724 epoch 16 batch 4 \n",
      "total loss: 0.98932284116745 epoch 16 batch 5 \n",
      "total loss: 0.899592399597168 epoch 16 batch 6 \n",
      "total loss: 1.0853971242904663 epoch 16 batch 7 \n",
      "total loss: 1.3030931949615479 epoch 16 batch 8 \n",
      "total loss: 1.1858594417572021 epoch 17 batch 1 \n",
      "total loss: 0.8357284069061279 epoch 17 batch 2 \n",
      "total loss: 1.0014313459396362 epoch 17 batch 3 \n",
      "total loss: 1.141481876373291 epoch 17 batch 4 \n",
      "total loss: 1.0812541246414185 epoch 17 batch 5 \n",
      "total loss: 0.7359268069267273 epoch 17 batch 6 \n",
      "total loss: 1.0458017587661743 epoch 17 batch 7 \n",
      "total loss: 0.8803959488868713 epoch 17 batch 8 \n",
      "total loss: 1.1047440767288208 epoch 18 batch 1 \n",
      "total loss: 0.44263458251953125 epoch 18 batch 2 \n",
      "total loss: 0.9225354194641113 epoch 18 batch 3 \n",
      "total loss: 0.8473376035690308 epoch 18 batch 4 \n",
      "total loss: 1.1947909593582153 epoch 18 batch 5 \n",
      "total loss: 1.184779167175293 epoch 18 batch 6 \n",
      "total loss: 1.016563057899475 epoch 18 batch 7 \n",
      "total loss: 0.9688467979431152 epoch 18 batch 8 \n",
      "total loss: 1.0202836990356445 epoch 19 batch 1 \n",
      "total loss: 0.9446675777435303 epoch 19 batch 2 \n",
      "total loss: 0.9973382353782654 epoch 19 batch 3 \n",
      "total loss: 0.8443421721458435 epoch 19 batch 4 \n",
      "total loss: 0.8341041207313538 epoch 19 batch 5 \n",
      "total loss: 0.715833306312561 epoch 19 batch 6 \n",
      "total loss: 0.9420205354690552 epoch 19 batch 7 \n",
      "total loss: 1.0154600143432617 epoch 19 batch 8 \n",
      "total loss: 0.740540623664856 epoch 20 batch 1 \n",
      "total loss: 0.8418120741844177 epoch 20 batch 2 \n",
      "total loss: 1.0732293128967285 epoch 20 batch 3 \n",
      "total loss: 0.9388717412948608 epoch 20 batch 4 \n",
      "total loss: 0.8366064429283142 epoch 20 batch 5 \n",
      "total loss: 0.8628606796264648 epoch 20 batch 6 \n",
      "total loss: 0.7378893494606018 epoch 20 batch 7 \n",
      "total loss: 0.8893099427223206 epoch 20 batch 8 \n",
      "total loss: 0.529234766960144 epoch 21 batch 1 \n",
      "total loss: 0.7867636680603027 epoch 21 batch 2 \n",
      "total loss: 0.9677551984786987 epoch 21 batch 3 \n",
      "total loss: 0.9791594743728638 epoch 21 batch 4 \n",
      "total loss: 0.7972344756126404 epoch 21 batch 5 \n",
      "total loss: 0.8678792119026184 epoch 21 batch 6 \n",
      "total loss: 0.5643497705459595 epoch 21 batch 7 \n",
      "total loss: 0.9876341223716736 epoch 21 batch 8 \n",
      "total loss: 0.7479971051216125 epoch 22 batch 1 \n",
      "total loss: 0.6291155815124512 epoch 22 batch 2 \n",
      "total loss: 0.8209879398345947 epoch 22 batch 3 \n",
      "total loss: 0.5798247456550598 epoch 22 batch 4 \n",
      "total loss: 0.7906522154808044 epoch 22 batch 5 \n",
      "total loss: 0.8988580107688904 epoch 22 batch 6 \n",
      "total loss: 0.6355898380279541 epoch 22 batch 7 \n",
      "total loss: 0.7329281568527222 epoch 22 batch 8 \n",
      "total loss: 0.5208448171615601 epoch 23 batch 1 \n",
      "total loss: 0.6100892424583435 epoch 23 batch 2 \n",
      "total loss: 0.574611246585846 epoch 23 batch 3 \n",
      "total loss: 0.7449652552604675 epoch 23 batch 4 \n",
      "total loss: 0.7273077368736267 epoch 23 batch 5 \n",
      "total loss: 0.60490882396698 epoch 23 batch 6 \n",
      "total loss: 0.728398859500885 epoch 23 batch 7 \n",
      "total loss: 0.6615520715713501 epoch 23 batch 8 \n",
      "total loss: 0.5405511260032654 epoch 24 batch 1 \n",
      "total loss: 0.589633047580719 epoch 24 batch 2 \n",
      "total loss: 0.46698251366615295 epoch 24 batch 3 \n",
      "total loss: 0.6074123382568359 epoch 24 batch 4 \n",
      "total loss: 0.6512640118598938 epoch 24 batch 5 \n",
      "total loss: 0.48317191004753113 epoch 24 batch 6 \n",
      "total loss: 0.6416177749633789 epoch 24 batch 7 \n",
      "total loss: 0.5467976331710815 epoch 24 batch 8 \n",
      "total loss: 0.4713214635848999 epoch 25 batch 1 \n",
      "total loss: 0.5229417681694031 epoch 25 batch 2 \n",
      "total loss: 0.41321301460266113 epoch 25 batch 3 \n",
      "total loss: 0.5336644649505615 epoch 25 batch 4 \n",
      "total loss: 0.47678887844085693 epoch 25 batch 5 \n",
      "total loss: 0.6449202299118042 epoch 25 batch 6 \n",
      "total loss: 0.6493931412696838 epoch 25 batch 7 \n",
      "total loss: 0.5313215851783752 epoch 25 batch 8 \n",
      "total loss: 0.6106650233268738 epoch 26 batch 1 \n",
      "total loss: 0.6026859283447266 epoch 26 batch 2 \n",
      "total loss: 0.46240168809890747 epoch 26 batch 3 \n",
      "total loss: 0.6444396376609802 epoch 26 batch 4 \n",
      "total loss: 0.4119205176830292 epoch 26 batch 5 \n",
      "total loss: 0.47174137830734253 epoch 26 batch 6 \n",
      "total loss: 0.535037636756897 epoch 26 batch 7 \n",
      "total loss: 0.5222252607345581 epoch 26 batch 8 \n",
      "total loss: 0.43694692850112915 epoch 27 batch 1 \n",
      "total loss: 0.40179914236068726 epoch 27 batch 2 \n",
      "total loss: 0.4717898666858673 epoch 27 batch 3 \n",
      "total loss: 0.4064114987850189 epoch 27 batch 4 \n",
      "total loss: 0.39311715960502625 epoch 27 batch 5 \n",
      "total loss: 0.4521748125553131 epoch 27 batch 6 \n",
      "total loss: 0.5842772126197815 epoch 27 batch 7 \n",
      "total loss: 0.45038214325904846 epoch 27 batch 8 \n",
      "total loss: 0.3325006067752838 epoch 28 batch 1 \n",
      "total loss: 0.3120167851448059 epoch 28 batch 2 \n",
      "total loss: 0.38051289319992065 epoch 28 batch 3 \n",
      "total loss: 0.4094117283821106 epoch 28 batch 4 \n",
      "total loss: 0.3805501163005829 epoch 28 batch 5 \n",
      "total loss: 0.3900003433227539 epoch 28 batch 6 \n",
      "total loss: 0.3950032591819763 epoch 28 batch 7 \n",
      "total loss: 0.3032248318195343 epoch 28 batch 8 \n",
      "total loss: 0.30717983841896057 epoch 29 batch 1 \n",
      "total loss: 0.22625508904457092 epoch 29 batch 2 \n",
      "total loss: 0.27918729186058044 epoch 29 batch 3 \n",
      "total loss: 0.3379271924495697 epoch 29 batch 4 \n",
      "total loss: 0.3041371703147888 epoch 29 batch 5 \n",
      "total loss: 0.36139556765556335 epoch 29 batch 6 \n",
      "total loss: 0.27743658423423767 epoch 29 batch 7 \n",
      "total loss: 0.30289390683174133 epoch 29 batch 8 \n",
      "total loss: 0.2599901258945465 epoch 30 batch 1 \n",
      "total loss: 0.1898958683013916 epoch 30 batch 2 \n",
      "total loss: 0.23404012620449066 epoch 30 batch 3 \n",
      "total loss: 0.216225728392601 epoch 30 batch 4 \n",
      "total loss: 0.2598634362220764 epoch 30 batch 5 \n",
      "total loss: 0.2838864028453827 epoch 30 batch 6 \n",
      "total loss: 0.25267350673675537 epoch 30 batch 7 \n",
      "total loss: 0.27944108843803406 epoch 30 batch 8 \n",
      "total loss: 0.254086971282959 epoch 31 batch 1 \n",
      "total loss: 0.18885403871536255 epoch 31 batch 2 \n",
      "total loss: 0.19382672011852264 epoch 31 batch 3 \n",
      "total loss: 0.21804986894130707 epoch 31 batch 4 \n",
      "total loss: 0.28778910636901855 epoch 31 batch 5 \n",
      "total loss: 0.22675399482250214 epoch 31 batch 6 \n",
      "total loss: 0.19106525182724 epoch 31 batch 7 \n",
      "total loss: 0.2393949031829834 epoch 31 batch 8 \n",
      "total loss: 0.21253135800361633 epoch 32 batch 1 \n",
      "total loss: 0.1722230613231659 epoch 32 batch 2 \n",
      "total loss: 0.22831517457962036 epoch 32 batch 3 \n",
      "total loss: 0.1659785807132721 epoch 32 batch 4 \n",
      "total loss: 0.17487753927707672 epoch 32 batch 5 \n",
      "total loss: 0.2737438380718231 epoch 32 batch 6 \n",
      "total loss: 0.21342992782592773 epoch 32 batch 7 \n",
      "total loss: 0.1909090131521225 epoch 32 batch 8 \n",
      "total loss: 0.16547785699367523 epoch 33 batch 1 \n",
      "total loss: 0.1942463368177414 epoch 33 batch 2 \n",
      "total loss: 0.15573261678218842 epoch 33 batch 3 \n",
      "total loss: 0.17389804124832153 epoch 33 batch 4 \n",
      "total loss: 0.14041370153427124 epoch 33 batch 5 \n",
      "total loss: 0.1493036448955536 epoch 33 batch 6 \n",
      "total loss: 0.18919570744037628 epoch 33 batch 7 \n",
      "total loss: 0.18246974050998688 epoch 33 batch 8 \n",
      "total loss: 0.12255778908729553 epoch 34 batch 1 \n",
      "total loss: 0.13042254745960236 epoch 34 batch 2 \n",
      "total loss: 0.12297865748405457 epoch 34 batch 3 \n",
      "total loss: 0.1373244673013687 epoch 34 batch 4 \n",
      "total loss: 0.12448514997959137 epoch 34 batch 5 \n",
      "total loss: 0.11622685939073563 epoch 34 batch 6 \n",
      "total loss: 0.16193749010562897 epoch 34 batch 7 \n",
      "total loss: 0.19462479650974274 epoch 34 batch 8 \n",
      "total loss: 0.12123673409223557 epoch 35 batch 1 \n",
      "total loss: 0.12171461433172226 epoch 35 batch 2 \n",
      "total loss: 0.12292692065238953 epoch 35 batch 3 \n",
      "total loss: 0.09630618244409561 epoch 35 batch 4 \n",
      "total loss: 0.09842904657125473 epoch 35 batch 5 \n",
      "total loss: 0.13473375141620636 epoch 35 batch 6 \n",
      "total loss: 0.14004850387573242 epoch 35 batch 7 \n",
      "total loss: 0.11318545043468475 epoch 35 batch 8 \n",
      "total loss: 0.11353657394647598 epoch 36 batch 1 \n",
      "total loss: 0.06402979791164398 epoch 36 batch 2 \n",
      "total loss: 0.09439920634031296 epoch 36 batch 3 \n",
      "total loss: 0.09746693074703217 epoch 36 batch 4 \n",
      "total loss: 0.1021106019616127 epoch 36 batch 5 \n",
      "total loss: 0.11104798316955566 epoch 36 batch 6 \n",
      "total loss: 0.11410000175237656 epoch 36 batch 7 \n",
      "total loss: 0.10272932797670364 epoch 36 batch 8 \n",
      "total loss: 0.06786186248064041 epoch 37 batch 1 \n",
      "total loss: 0.07124260067939758 epoch 37 batch 2 \n",
      "total loss: 0.07791471481323242 epoch 37 batch 3 \n",
      "total loss: 0.07016269117593765 epoch 37 batch 4 \n",
      "total loss: 0.06754015386104584 epoch 37 batch 5 \n",
      "total loss: 0.13434313237667084 epoch 37 batch 6 \n",
      "total loss: 0.1161305233836174 epoch 37 batch 7 \n",
      "total loss: 0.11972096562385559 epoch 37 batch 8 \n",
      "total loss: 0.06616125255823135 epoch 38 batch 1 \n",
      "total loss: 0.07736718654632568 epoch 38 batch 2 \n",
      "total loss: 0.06786392629146576 epoch 38 batch 3 \n",
      "total loss: 0.07740513980388641 epoch 38 batch 4 \n",
      "total loss: 0.08681163191795349 epoch 38 batch 5 \n",
      "total loss: 0.07527171820402145 epoch 38 batch 6 \n",
      "total loss: 0.09884009510278702 epoch 38 batch 7 \n",
      "total loss: 0.08380645513534546 epoch 38 batch 8 \n",
      "total loss: 0.07128647714853287 epoch 39 batch 1 \n",
      "total loss: 0.0697663351893425 epoch 39 batch 2 \n",
      "total loss: 0.0881924033164978 epoch 39 batch 3 \n",
      "total loss: 0.059818021953105927 epoch 39 batch 4 \n",
      "total loss: 0.09232046455144882 epoch 39 batch 5 \n",
      "total loss: 0.08523343503475189 epoch 39 batch 6 \n",
      "total loss: 0.07323113828897476 epoch 39 batch 7 \n",
      "total loss: 0.07977164536714554 epoch 39 batch 8 \n",
      "total loss: 0.06284601241350174 epoch 40 batch 1 \n",
      "total loss: 0.07593806833028793 epoch 40 batch 2 \n",
      "total loss: 0.061175502836704254 epoch 40 batch 3 \n",
      "total loss: 0.06694114953279495 epoch 40 batch 4 \n",
      "total loss: 0.0955595150589943 epoch 40 batch 5 \n",
      "total loss: 0.06582149118185043 epoch 40 batch 6 \n",
      "total loss: 0.05644078552722931 epoch 40 batch 7 \n",
      "total loss: 0.0910230427980423 epoch 40 batch 8 \n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "from collections import defaultdict\n",
    "data = defaultdict(list)\n",
    "\n",
    "for i in range(1, epochs+1):\n",
    "\n",
    "    encoder_initial_cell_state = initialize_initial_state()\n",
    "    total_loss = 0.0\n",
    "\n",
    "\n",
    "    for ( batch , (input_batch, output_batch)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        #encoder_initial_cell_state = initialize_initial_state() # TODO\n",
    "        batch_loss = train_step(input_batch, output_batch, encoder_initial_cell_state)\n",
    "        total_loss += batch_loss\n",
    "#        if (batch+1)%20 == 0:\n",
    "        print(\"total loss: {} epoch {} batch {} \".format(batch_loss.numpy(), i, batch+1))\n",
    "            #checkpoint.save(file_prefix = chkpoint_prefix)\n",
    "        data['batch'].append(total_loss)\n",
    "    data['epoch'].append(total_loss)\n",
    "    #print(data['epoch'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1697fbcc0>]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data['batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total loss: 0.23502042889595032 epoch 40 batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15f661400>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 1024])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_initial_cell_state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 15, 15, 15]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE*[Tx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "Create input sequence to pass to encoder.\n",
    "\n",
    "The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
    "\n",
    "Stop predicting when the model predicts the end token.\n",
    "\n",
    "And store the attention weights for every time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 256)\n"
     ]
    }
   ],
   "source": [
    "#if trained in same session else use checkpoint variable\n",
    "#decoder_embedding_matrix = tf.train.load_variable(checkpointdir, 'decoderNetwork/decoder_embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE')\n",
    "decoder_embedding_matrix = decoderNetwork.decoder_embedding.variables[0] \n",
    "print(decoderNetwork.decoder_embedding.variables[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if restoring from checkpoint, lets print all variables related to decoder_embeddings and then select and load the right variable containing decoder embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [print(var) for var in tf.train.list_variables(\n",
    "#     checkpointdir) if re.match(r'.*decoder_embedding.*',var[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_embedding_matrix = tf.train.load_variable(\n",
    "#     checkpointdir, 'decoderNetwork/decoder_embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE')\n",
    "# print(decoder_embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_tx : (2, 1024)\n",
      "c_tx : (2, 1024)\n",
      "decoder_initial_state = [a_tx, c_tx] : (2, 2, 1024)\n",
      "\n",
      "Compared to simple encoder-decoder without attention, the decoder_initial_state  is an AttentionWrapperState object containing s_prev tensors and context and alignment vector \n",
      " \n",
      "decoder initial state shape : (6,)\n",
      "decoder_initial_state tensor \n",
      " AttentionWrapperState(cell_state=[<tf.Tensor: shape=(2, 1024), dtype=float32, numpy=\n",
      "array([[ 0.0518618 , -0.14032008, -0.10341083, ..., -0.00112762,\n",
      "        -0.04448861,  0.03323371],\n",
      "       [ 0.0518618 , -0.14032008, -0.10341083, ..., -0.00112762,\n",
      "        -0.0444886 ,  0.03323371]], dtype=float32)>, <tf.Tensor: shape=(2, 1024), dtype=float32, numpy=\n",
      "array([[ 0.12939554, -0.32432944, -0.21965227, ..., -0.00250256,\n",
      "        -0.09040678,  0.06978433],\n",
      "       [ 0.12939553, -0.32432944, -0.21965227, ..., -0.00250257,\n",
      "        -0.09040677,  0.06978431]], dtype=float32)>], attention=<tf.Tensor: shape=(2, 1024), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, time=<tf.Tensor: shape=(), dtype=int32, numpy=0>, alignments=<tf.Tensor: shape=(2, 152), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>, alignment_history=(), attention_state=<tf.Tensor: shape=(2, 152), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>)\n",
      "\n",
      "first_inputs returns the same decoder_input i.e. embedding of  <start> : (2, 256)\n",
      "start_index_emb_avg  tf.Tensor(0.751768, shape=(), dtype=float32)\n",
      "\n",
      " predictions shape: (2, 0)\n",
      "\n",
      " predictions: []\n"
     ]
    }
   ],
   "source": [
    "#use with scope /cpu:0 for inferencing\n",
    "#restore from latest checkpoint for inferencing\n",
    "input_raw=\"1  \\nx\"\n",
    "#input_raw=\"Wow!\"  #checking translation on training set record\n",
    "#def inference(input_raw):\n",
    "input_lines = input_raw.split(\"\\n\")\n",
    "\n",
    "# Preprocess X\n",
    "input_lines = [preprocess_sentence(line) for line in input_lines]\n",
    "input_sequences = [[X_tokenizer.word_index[w] for w in line.split(' ')] for line in input_lines]\n",
    "input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences,\n",
    "                                                                maxlen=Tx, padding='post')\n",
    "inp = tf.convert_to_tensor(input_sequences)\n",
    "#print(inp.shape)\n",
    "inference_batch_size = input_sequences.shape[0]\n",
    "encoder_initial_cell_state = [tf.zeros((inference_batch_size, rnn_units)),\n",
    "                              tf.zeros((inference_batch_size, rnn_units))]\n",
    "encoder_emb_inp = encoderNetwork.encoder_embedding(inp)\n",
    "a, a_tx, c_tx = encoderNetwork.encoder_rnnlayer(encoder_emb_inp,\n",
    "                                                initial_state =encoder_initial_cell_state)\n",
    "\n",
    "\n",
    "#output_sequences = []\n",
    "print('a_tx :',a_tx.shape)\n",
    "print('c_tx :', c_tx.shape)\n",
    "\n",
    "\n",
    "\n",
    "start_tokens = tf.fill([inference_batch_size],Y_tokenizer.word_index['<start>'])\n",
    "#print(start_tokens)\n",
    "end_token = Y_tokenizer.word_index['<end>']\n",
    "\n",
    "greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
    "#finished,start_inputs = greedy_sampler.initialize(decoder_embedding_matrix,start_tokens,end_token)\n",
    "#print(finished.shape, start_inputs.shape)\n",
    "\n",
    "decoder_input = tf.expand_dims([Y_tokenizer.word_index['<start>']]* inference_batch_size,1)\n",
    "\n",
    "decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_input)\n",
    "\n",
    "decoder_instance = tfa.seq2seq.BasicDecoder(cell = decoderNetwork.rnn_cell, sampler = greedy_sampler,\n",
    "                                            output_layer=decoderNetwork.dense_layer)\n",
    "decoderNetwork.attention_mechanism.setup_memory(a)\n",
    "#pass [ last step activations , encoder memory_state ] as input to decoder for LSTM\n",
    "print(\"decoder_initial_state = [a_tx, c_tx] :\",np.array([a_tx, c_tx]).shape)\n",
    "decoder_initial_state = decoderNetwork.build_decoder_initial_state(inference_batch_size,\n",
    "                                                                   encoder_state=[a_tx, c_tx],\n",
    "                                                                   Dtype=tf.float32)\n",
    "print(\"\\nCompared to simple encoder-decoder without attention, the decoder_initial_state \\\n",
    " is an AttentionWrapperState object containing s_prev tensors and context and alignment vector \\n \")\n",
    "print(\"decoder initial state shape :\",np.array(decoder_initial_state).shape)\n",
    "print(\"decoder_initial_state tensor \\n\", decoder_initial_state)\n",
    "\n",
    "# Since we do not know the target sequence lengths in advance, we use maximum_iterations to limit the translation lengths.\n",
    "# One heuristic is to decode up to two times the source sentence lengths.\n",
    "maximum_iterations = tf.round(tf.reduce_max(Tx) * 2)\n",
    "\n",
    "#initialize inference decoder\n",
    "\n",
    "(first_finished, first_inputs,first_state) = decoder_instance.initialize(decoder_embedding_matrix,\n",
    "                             start_tokens = start_tokens,\n",
    "                             end_token=end_token,\n",
    "                             initial_state = decoder_initial_state)\n",
    "#print( first_finished.shape)\n",
    "print(\"\\nfirst_inputs returns the same decoder_input i.e. embedding of  <start> :\",first_inputs.shape)\n",
    "print(\"start_index_emb_avg \", tf.reduce_sum(tf.reduce_mean(first_inputs, axis=0))) # mean along the batch\n",
    "\n",
    "inputs = first_inputs\n",
    "state = first_state  \n",
    "predictions = np.empty((inference_batch_size,0), dtype = np.int32) \n",
    "\n",
    "print(\"\\n predictions shape:\", predictions.shape)\n",
    "print(\"\\n predictions:\", predictions)\n",
    "\n",
    "for j in range(maximum_iterations):\n",
    "    outputs, next_state, next_inputs, finished = decoder_instance.step(j,inputs,state)\n",
    "    inputs = next_inputs\n",
    "    state = next_state\n",
    "    outputs = np.expand_dims(outputs.sample_id,axis = -1)\n",
    "    predictions = np.append(predictions, outputs, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard translations on encountering first sequence \\<end\\> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_token = Y_tokenizer.word_index['<end>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equation:\n",
      "1  \n",
      "x\n",
      "\n",
      "Integral Equation:\n",
      "+ / -1 8 + * -1 x + * -9 pow cos 4 -1 * / 1 4 * pi acos 4\n",
      "+ * -1 x + * / -1 4 tanh 2 * / 1 4 cosh 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Equation:\")\n",
    "print(input_raw)\n",
    "integral_seq = []\n",
    "print(\"\\nIntegral Equation:\")\n",
    "for i in range(len(predictions)):\n",
    "    line = predictions[i,:]\n",
    "    seq = list(itertools.takewhile( lambda index: index !=end_token, line))\n",
    "    output = \" \".join( [Y_tokenizer.index_word[w] for w in seq])\n",
    "    integral_seq.append(output)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -1 ) / 8 + ( -1 ) * x + -9 * cos ( 4 ) ** -1 + 1 / 4 * pi * acos ( 4 )\n",
      "-x - 1/8 - 9/cos(4) + pi*acos(4)/4\n",
      "( -1 ) * x + -1 / 4 * tanh ( 2 ) + 1 / 4 * cosh ( 4 )\n",
      "-x - tanh(2)/4 + cosh(4)/4\n"
     ]
    }
   ],
   "source": [
    "from infix_prefix1 import prefix_to_infix\n",
    "from sympy import *\n",
    "from sympy.parsing.sympy_parser import parse_expr\n",
    "\n",
    "x = symbols('x', real=True)\n",
    "\n",
    "for ele in integral_seq:\n",
    "    result_infix = prefix_to_infix(ele)\n",
    "    result_infix = result_infix.replace(\"pow\", \"**\")\n",
    "    print(result_infix)\n",
    "    result_simp = simplify(parse_expr(result_infix, local_dict={'x': x}))\n",
    "    print(result_simp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference using Beam Search with beam_width = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam_with * [batch_size, Tx, rnn_units] :  3 * [2, Tx, rnn_units]] : (10, 152, 1024)\n",
      "\n",
      "first_inputs returns the same decoder_input i.e. embedding of  <start> : (2, 5, 256)\n",
      "(2, 5, 304)\n",
      "(2, 5, 304)\n"
     ]
    }
   ],
   "source": [
    "beam_width = 5\n",
    "#use with scope /cpu:0 for inferencing\n",
    "#restore from latest checkpoint for inferencing\n",
    "input_raw=\"1  \\nx\"\n",
    "#input_raw=\"Wow!\"  #checking translation on training set record\n",
    "#def inference(input_raw):\n",
    "input_lines = input_raw.split(\"\\n\")\n",
    "# We have a transcript file containing English-Hindi pairs\n",
    "# Preprocess X\n",
    "input_lines = [preprocess_sentence(line) for line in input_lines]\n",
    "input_sequences = [[X_tokenizer.word_index[w] for w in line.split(' ')] for line in input_lines]\n",
    "input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences,\n",
    "                                                                maxlen=Tx, padding='post')\n",
    "inp = tf.convert_to_tensor(input_sequences)\n",
    "#print(inp.shape)\n",
    "inference_batch_size = input_sequences.shape[0]\n",
    "encoder_initial_cell_state = [tf.zeros((inference_batch_size, rnn_units)),\n",
    "                              tf.zeros((inference_batch_size, rnn_units))]\n",
    "encoder_emb_inp = encoderNetwork.encoder_embedding(inp)\n",
    "a, a_tx, c_tx = encoderNetwork.encoder_rnnlayer(encoder_emb_inp,\n",
    "                                                initial_state =encoder_initial_cell_state)\n",
    "\n",
    "start_tokens = tf.fill([inference_batch_size],Y_tokenizer.word_index['<start>'])\n",
    "#print(start_tokens)\n",
    "end_token = Y_tokenizer.word_index['<end>']\n",
    "\n",
    "\n",
    "\n",
    "decoder_input = tf.expand_dims([Y_tokenizer.word_index['<start>']]* inference_batch_size,1)\n",
    "decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_input)\n",
    "\n",
    "\n",
    "#From official documentation\n",
    "#NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:\n",
    "\n",
    "#The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).\n",
    "#The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.\n",
    "#The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.\n",
    "encoder_memory = tfa.seq2seq.tile_batch(a, beam_width)\n",
    "decoderNetwork.attention_mechanism.setup_memory(encoder_memory)\n",
    "print(\"beam_with * [batch_size, Tx, rnn_units] :  3 * [2, Tx, rnn_units]] :\", encoder_memory.shape)\n",
    "#set decoder_inital_state which is an AttentionWrapperState considering beam_width\n",
    "decoder_initial_state = decoderNetwork.rnn_cell.get_initial_state(batch_size = inference_batch_size* beam_width,dtype = Dtype)\n",
    "encoder_state = tfa.seq2seq.tile_batch([a_tx, c_tx], multiplier=beam_width)\n",
    "decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state) \n",
    "\n",
    "decoder_instance = tfa.seq2seq.BeamSearchDecoder(decoderNetwork.rnn_cell,beam_width=beam_width,\n",
    "                                                 output_layer=decoderNetwork.dense_layer)\n",
    "\n",
    "\n",
    "# Since we do not know the target sequence lengths in advance, we use maximum_iterations to limit the translation lengths.\n",
    "# One heuristic is to decode up to two times the source sentence lengths.\n",
    "maximum_iterations = tf.round(tf.reduce_max(Tx) * 2)\n",
    "\n",
    "#initialize inference decoder\n",
    "\n",
    "(first_finished, first_inputs,first_state) = decoder_instance.initialize(decoder_embedding_matrix,\n",
    "                             start_tokens = start_tokens,\n",
    "                             end_token=end_token,\n",
    "                             initial_state = decoder_initial_state)\n",
    "#print( first_finished.shape)\n",
    "print(\"\\nfirst_inputs returns the same decoder_input i.e. embedding of  <start> :\",first_inputs.shape)\n",
    "\n",
    "inputs = first_inputs\n",
    "state = first_state  \n",
    "predictions = np.empty((inference_batch_size, beam_width,0), dtype = np.int32)\n",
    "beam_scores =  np.empty((inference_batch_size, beam_width,0), dtype = np.float32)                                                                            \n",
    "for j in range(maximum_iterations):\n",
    "    beam_search_outputs, next_state, next_inputs, finished = decoder_instance.step(j,inputs,state)\n",
    "    inputs = next_inputs\n",
    "    state = next_state\n",
    "    outputs = np.expand_dims(beam_search_outputs.predicted_ids,axis = -1)\n",
    "    scores = np.expand_dims(beam_search_outputs.scores,axis = -1)\n",
    "    predictions = np.append(predictions, outputs, axis = -1)\n",
    "    beam_scores = np.append(beam_scores, scores, axis = -1)\n",
    "print(predictions.shape) \n",
    "print(beam_scores.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Equation:\n",
      "1  \n",
      "x\n",
      "-----------------\n",
      "\n",
      "Integral Equation:\n",
      "---------------------------------------------\n",
      "+ / -1 8 + * -1 x + * -9 pow cos 4 -1 * / 1 4 * -1  beam score:  -43.3278\n",
      "* -1 * 6 * pow asinh asinh + 5 * -8 pow sin 3 -1 -1 pow log 2 pi acos 4  beam score:  -57.305958\n",
      "exp x * pow sinh 5 -1 + * -1 acosh  beam score:  -31.449848\n",
      "tan * atan atan  beam score:  -12.818518\n",
      "cosh -3 -1 x * / 48 5 * pow acosh / -7 2 -1 + 4 asinh 2 sinh tanh x  beam score:  -69.38785\n",
      "---------------------------------------------\n",
      "+ * -1 x + * / -1 4 tanh 2 * / 1 4 cosh 4  beam score:  -24.137402\n",
      "* -1 -1 pow + * -1 x + * -9 pow cos 4 -1 * / 1 4 * pi acos 4  beam score:  -53.936237\n",
      "exp / * 8 sinh 5 -1 + * -1 acosh -5 + * x sinh 5 tanh 10  beam score:  -47.55332\n",
      "tan 5 + * -1 pow x -1 + * -1 atan 2 + * -1 atanh 4 * -1 sinh 4  beam score:  -75.83485\n",
      "cosh -3 + * 5 cos tan / 25 17 * / -1 2 x  beam score:  -56.12629\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------\")\n",
    "print(\"Equation:\")\n",
    "print(input_raw)\n",
    "print(\"-----------------\")\n",
    "print(\"\\nIntegral Equation:\")\n",
    "for i in range(len(predictions)):\n",
    "    print(\"---------------------------------------------\")\n",
    "    output_beams_per_sample = predictions[i,:,:]\n",
    "    score_beams_per_sample = beam_scores[i,:,:]\n",
    "    for beam, score in zip(output_beams_per_sample,score_beams_per_sample) :\n",
    "        seq = list(itertools.takewhile( lambda index: index !=end_token, beam))\n",
    "        score_indexes = np.arange(len(seq))\n",
    "        beam_score = score[score_indexes].sum()\n",
    "        print(\" \".join( [Y_tokenizer.index_word[w] for w in seq]), \" beam score: \", beam_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(input_batch, output_batch,encoder_initial_cell_state, BATCH_SIZE):\n",
    "    #initialize loss = 0\n",
    "    loss = 0\n",
    "\n",
    "    # we can do initialization in outer block\n",
    "    #encoder_initial_cell_state = encoder.initialize_initial_state()\n",
    "    encoder_emb_inp = encoderNetwork.encoder_embedding(input_batch)\n",
    "    a, h_tx, c_tx = encoderNetwork.encoder_rnnlayer(encoder_emb_inp, \n",
    "                                                    initial_state =encoder_initial_cell_state)\n",
    "\n",
    "\n",
    "\n",
    "    decoder_input = output_batch[:,:-1] # ignore <end>\n",
    "    #compare logits with timestepped +1 version of decoder_input\n",
    "    decoder_output = output_batch[:,1:] #ignore <start>\n",
    "    decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_input)\n",
    "    decoder_instance = tfa.seq2seq.BasicDecoder(decoderNetwork.rnn_cell, \n",
    "                                                greedy_sampler,\n",
    "                                                decoderNetwork.dense_layer)\n",
    "    #BasicDecoderOutput\n",
    "\n",
    "    decoderNetwork.attention_mechanism.setup_memory(a)\n",
    "    #pass [ last step activations , encoder memory_state ] as input to decoder for LSTM\n",
    "    \n",
    "    decoder_initial_state = decoderNetwork.build_decoder_initial_state(BATCH_SIZE,\n",
    "                                                                       encoder_state=[h_tx, c_tx],\n",
    "                                                                       Dtype=tf.float32)\n",
    "    outputs, _, _ = decoderNetwork.decoder(decoder_emb_inp,initial_state=decoder_initial_state,\n",
    "                                           sequence_length=BATCH_SIZE*[Ty-1])\n",
    "    logits = outputs.rnn_output\n",
    "    sample_id = outputs.sample_id\n",
    "    #Calculate loss\n",
    "    loss = loss_function(logits, decoder_output)\n",
    "    return loss, sample_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Loss on Entire Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 152)\n",
      "Training loss 2.277127504348755\n"
     ]
    }
   ],
   "source": [
    "dataset_test = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(len(X_test))\n",
    "for (input_batch, output_batch) in dataset_test.take(-1):\n",
    "    batch_size = len(input_batch)\n",
    "    print(input_batch.shape)\n",
    "    encoder_initial_cell_state = [tf.zeros((batch_size, rnn_units)),\n",
    "                                  tf.zeros((batch_size, rnn_units))]\n",
    "    loss,_ = eval_step(input_batch, output_batch, encoder_initial_cell_state, batch_size)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    print(\"Training loss {}\".format(loss) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5], shape=(1,), dtype=int32)\n",
      "(1, 256)\n",
      "0.751768\n"
     ]
    }
   ],
   "source": [
    "#BasicDecoder initialization returns the <start> sequence as first_input\n",
    "#Check Inference Cell output\n",
    "\n",
    "start_index = Y_tokenizer.word_index['<start>']\n",
    "start_index = tf.constant([start_index], dtype = tf.int32)\n",
    "print(start_index)\n",
    "start_index_emb = decoderNetwork.decoder_embedding(start_index)\n",
    "print(start_index_emb.shape)\n",
    "start_index_emb_avg = tf.reduce_sum(start_index_emb)\n",
    "print(start_index_emb_avg.numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symbolic_math",
   "language": "python",
   "name": "symbolic_math"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
